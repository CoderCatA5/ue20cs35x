{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading csv from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./nlp-getting-started/train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orginal Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df=df['text']\n",
    "text_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Our Deeds are the Reason of this #earthquake ...\n",
       "1            [Forest fire near La Ronge Sask., Canada]\n",
       "2    [All residents asked to 'shelter in place' are...\n",
       "3    [13,000 people receive #wildfires evacuation o...\n",
       "4    [Just got sent this photo from Ruby #Alaska as...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df=text_df.apply(sent_tokenize)\n",
    "sent_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Our, Deeds, are, the, Reason, of, this, earth...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2    [All, residents, asked, to, shelter, in, place...\n",
       "3    [13, 000, people, receive, wildfires, evacuati...\n",
       "4    [Just, got, sent, this, photo, from, Ruby, Ala...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "word_df=text_df.apply(tokenizer.tokenize)\n",
    "word_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stop_words(wordList:list)-> list:\n",
    "    ansLis=[]\n",
    "    for i in wordList:\n",
    "        if i not in stop_words:\n",
    "            ansLis.append(i)\n",
    "    return ansLis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Our, Deeds, Reason, earthquake, May, ALLAH, F...\n",
       "1        [Forest, fire, near, La, Ronge, Sask, Canada]\n",
       "2    [All, residents, asked, shelter, place, notifi...\n",
       "3    [13, 000, people, receive, wildfires, evacuati...\n",
       "4    [Just, got, sent, photo, Ruby, Alaska, smoke, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df=word_df.apply(filter_stop_words)\n",
    "filtered_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(wordList:list)-> list:\n",
    "    ansLis=[]\n",
    "    for i in wordList:\n",
    "        ansLis.append(PorterStemmer().stem(i))\n",
    "    return ansLis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [our, deed, are, the, reason, of, thi, earthqu...\n",
       "1         [forest, fire, near, la, rong, sask, canada]\n",
       "2    [all, resid, ask, to, shelter, in, place, are,...\n",
       "3    [13, 000, peopl, receiv, wildfir, evacu, order...\n",
       "4    [just, got, sent, thi, photo, from, rubi, alas...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_df=word_df.apply(word_stemmer)\n",
    "stem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "675e5e662f103e0f338aafe09665377a2c199018438416d404abaa898c5fcab6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
