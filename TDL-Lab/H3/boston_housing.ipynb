{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = preprocessing.scale(x_train) \n",
    "scaler = preprocessing.StandardScaler().fit(x_train) \n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "x_test=x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    Dense(128,kernel_initializer=\"normal\",activation=\"relu\",input_shape=(13,1)),\n",
    "    Dense(32,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "#CFE\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=RMSprop(),\n",
    "    metrics=['mean_absolute_error','accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 13, 128)           256       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 13, 32)            4128      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 13, 1)             33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,417\n",
      "Trainable params: 4,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 567.9041 - mean_absolute_error: 21.9944 - accuracy: 0.0000e+00 - val_loss: 634.6533 - val_mean_absolute_error: 23.4546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 561.5861 - mean_absolute_error: 21.8495 - accuracy: 0.0000e+00 - val_loss: 628.6720 - val_mean_absolute_error: 23.3265 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 555.9329 - mean_absolute_error: 21.7197 - accuracy: 0.0000e+00 - val_loss: 622.6312 - val_mean_absolute_error: 23.1963 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 550.1382 - mean_absolute_error: 21.5852 - accuracy: 0.0000e+00 - val_loss: 616.0900 - val_mean_absolute_error: 23.0545 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 543.7823 - mean_absolute_error: 21.4375 - accuracy: 0.0000e+00 - val_loss: 608.9087 - val_mean_absolute_error: 22.8976 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 536.8770 - mean_absolute_error: 21.2752 - accuracy: 0.0000e+00 - val_loss: 601.1456 - val_mean_absolute_error: 22.7268 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 529.4995 - mean_absolute_error: 21.0981 - accuracy: 0.0000e+00 - val_loss: 592.9385 - val_mean_absolute_error: 22.5446 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 521.6016 - mean_absolute_error: 20.9110 - accuracy: 0.0000e+00 - val_loss: 584.0401 - val_mean_absolute_error: 22.3454 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 513.1046 - mean_absolute_error: 20.7067 - accuracy: 0.0000e+00 - val_loss: 574.5656 - val_mean_absolute_error: 22.1311 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 504.1487 - mean_absolute_error: 20.4842 - accuracy: 0.0000e+00 - val_loss: 564.6760 - val_mean_absolute_error: 21.9050 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 494.7216 - mean_absolute_error: 20.2526 - accuracy: 0.0000e+00 - val_loss: 554.1166 - val_mean_absolute_error: 21.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 484.7124 - mean_absolute_error: 20.0019 - accuracy: 0.0000e+00 - val_loss: 543.0394 - val_mean_absolute_error: 21.4015 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 474.1744 - mean_absolute_error: 19.7376 - accuracy: 0.0000e+00 - val_loss: 531.2333 - val_mean_absolute_error: 21.1214 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 463.2354 - mean_absolute_error: 19.4483 - accuracy: 0.0000e+00 - val_loss: 518.9951 - val_mean_absolute_error: 20.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 451.5590 - mean_absolute_error: 19.1514 - accuracy: 0.0000e+00 - val_loss: 506.2316 - val_mean_absolute_error: 20.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 439.6969 - mean_absolute_error: 18.8318 - accuracy: 0.0000e+00 - val_loss: 493.2968 - val_mean_absolute_error: 20.1942 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 427.3847 - mean_absolute_error: 18.5063 - accuracy: 0.0000e+00 - val_loss: 479.4922 - val_mean_absolute_error: 19.8454 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 414.7311 - mean_absolute_error: 18.1517 - accuracy: 0.0000e+00 - val_loss: 465.6939 - val_mean_absolute_error: 19.4905 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 401.9764 - mean_absolute_error: 17.7906 - accuracy: 0.0000e+00 - val_loss: 451.6460 - val_mean_absolute_error: 19.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 388.9904 - mean_absolute_error: 17.4164 - accuracy: 0.0000e+00 - val_loss: 437.3035 - val_mean_absolute_error: 18.7391 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 375.6853 - mean_absolute_error: 17.0340 - accuracy: 0.0000e+00 - val_loss: 422.4347 - val_mean_absolute_error: 18.3339 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 362.0950 - mean_absolute_error: 16.6265 - accuracy: 0.0000e+00 - val_loss: 407.5994 - val_mean_absolute_error: 17.9214 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 348.5781 - mean_absolute_error: 16.2156 - accuracy: 0.0000e+00 - val_loss: 392.6118 - val_mean_absolute_error: 17.4952 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 334.8502 - mean_absolute_error: 15.7899 - accuracy: 0.0000e+00 - val_loss: 377.3571 - val_mean_absolute_error: 17.0516 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 320.9432 - mean_absolute_error: 15.3535 - accuracy: 0.0000e+00 - val_loss: 361.8540 - val_mean_absolute_error: 16.5903 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 306.9414 - mean_absolute_error: 14.9060 - accuracy: 0.0000e+00 - val_loss: 346.3492 - val_mean_absolute_error: 16.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 293.0446 - mean_absolute_error: 14.4464 - accuracy: 0.0000e+00 - val_loss: 330.9506 - val_mean_absolute_error: 15.6394 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 279.3595 - mean_absolute_error: 13.9801 - accuracy: 0.0000e+00 - val_loss: 315.6771 - val_mean_absolute_error: 15.1577 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 265.8461 - mean_absolute_error: 13.5118 - accuracy: 0.0000e+00 - val_loss: 300.6251 - val_mean_absolute_error: 14.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 252.5074 - mean_absolute_error: 13.0423 - accuracy: 0.0000e+00 - val_loss: 285.5199 - val_mean_absolute_error: 14.1669 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 239.2753 - mean_absolute_error: 12.5731 - accuracy: 0.0000e+00 - val_loss: 270.5179 - val_mean_absolute_error: 13.6533 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 226.7065 - mean_absolute_error: 12.1052 - accuracy: 0.0000e+00 - val_loss: 256.8140 - val_mean_absolute_error: 13.1708 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 214.5613 - mean_absolute_error: 11.6581 - accuracy: 0.0000e+00 - val_loss: 242.8029 - val_mean_absolute_error: 12.6632 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 202.6675 - mean_absolute_error: 11.2079 - accuracy: 0.0000e+00 - val_loss: 229.0170 - val_mean_absolute_error: 12.1511 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 191.1375 - mean_absolute_error: 10.7564 - accuracy: 0.0000e+00 - val_loss: 215.8746 - val_mean_absolute_error: 11.6491 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 180.1794 - mean_absolute_error: 10.3297 - accuracy: 0.0000e+00 - val_loss: 203.2732 - val_mean_absolute_error: 11.1551 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 169.7701 - mean_absolute_error: 9.9093 - accuracy: 0.0000e+00 - val_loss: 191.2213 - val_mean_absolute_error: 10.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 160.1344 - mean_absolute_error: 9.4941 - accuracy: 0.0000e+00 - val_loss: 180.4080 - val_mean_absolute_error: 10.2414 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 151.4751 - mean_absolute_error: 9.1362 - accuracy: 0.0000e+00 - val_loss: 169.5070 - val_mean_absolute_error: 9.7982 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 143.0519 - mean_absolute_error: 8.7896 - accuracy: 0.0000e+00 - val_loss: 160.2531 - val_mean_absolute_error: 9.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 136.0626 - mean_absolute_error: 8.4976 - accuracy: 0.0000e+00 - val_loss: 150.7746 - val_mean_absolute_error: 9.0246 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 128.9347 - mean_absolute_error: 8.2012 - accuracy: 0.0000e+00 - val_loss: 142.5558 - val_mean_absolute_error: 8.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 123.0020 - mean_absolute_error: 7.9619 - accuracy: 0.0000e+00 - val_loss: 135.3261 - val_mean_absolute_error: 8.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 117.7969 - mean_absolute_error: 7.7369 - accuracy: 0.0000e+00 - val_loss: 128.6546 - val_mean_absolute_error: 8.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 113.2908 - mean_absolute_error: 7.5739 - accuracy: 0.0000e+00 - val_loss: 123.0706 - val_mean_absolute_error: 7.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 109.3353 - mean_absolute_error: 7.3952 - accuracy: 0.0000e+00 - val_loss: 118.1123 - val_mean_absolute_error: 7.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 106.1560 - mean_absolute_error: 7.2719 - accuracy: 0.0000e+00 - val_loss: 113.0350 - val_mean_absolute_error: 7.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 102.7892 - mean_absolute_error: 7.1436 - accuracy: 0.0000e+00 - val_loss: 109.0639 - val_mean_absolute_error: 7.2557 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 100.4200 - mean_absolute_error: 7.0544 - accuracy: 0.0000e+00 - val_loss: 105.6826 - val_mean_absolute_error: 7.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 98.2306 - mean_absolute_error: 6.9884 - accuracy: 0.0000e+00 - val_loss: 102.6395 - val_mean_absolute_error: 7.0265 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 96.4237 - mean_absolute_error: 6.9278 - accuracy: 0.0000e+00 - val_loss: 100.2556 - val_mean_absolute_error: 6.9511 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 95.0513 - mean_absolute_error: 6.8935 - accuracy: 0.0000e+00 - val_loss: 98.8051 - val_mean_absolute_error: 6.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 94.0122 - mean_absolute_error: 6.8765 - accuracy: 0.0000e+00 - val_loss: 97.6586 - val_mean_absolute_error: 6.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 93.2400 - mean_absolute_error: 6.8495 - accuracy: 0.0000e+00 - val_loss: 96.3700 - val_mean_absolute_error: 6.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 92.1118 - mean_absolute_error: 6.8165 - accuracy: 0.0000e+00 - val_loss: 94.9018 - val_mean_absolute_error: 6.7977 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 91.4051 - mean_absolute_error: 6.8068 - accuracy: 0.0000e+00 - val_loss: 93.5490 - val_mean_absolute_error: 6.7739 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 90.5704 - mean_absolute_error: 6.8019 - accuracy: 0.0000e+00 - val_loss: 92.3034 - val_mean_absolute_error: 6.7566 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 90.0068 - mean_absolute_error: 6.8007 - accuracy: 0.0000e+00 - val_loss: 91.6748 - val_mean_absolute_error: 6.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 89.4283 - mean_absolute_error: 6.7837 - accuracy: 0.0000e+00 - val_loss: 90.9376 - val_mean_absolute_error: 6.7223 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 89.0916 - mean_absolute_error: 6.7973 - accuracy: 0.0000e+00 - val_loss: 91.6171 - val_mean_absolute_error: 6.7031 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 88.6313 - mean_absolute_error: 6.7267 - accuracy: 0.0000e+00 - val_loss: 90.3898 - val_mean_absolute_error: 6.6922 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 88.2195 - mean_absolute_error: 6.7757 - accuracy: 0.0000e+00 - val_loss: 91.0764 - val_mean_absolute_error: 6.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 87.8955 - mean_absolute_error: 6.7156 - accuracy: 0.0000e+00 - val_loss: 91.1986 - val_mean_absolute_error: 6.6671 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 87.4876 - mean_absolute_error: 6.6724 - accuracy: 0.0000e+00 - val_loss: 89.6424 - val_mean_absolute_error: 6.6577 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 87.1924 - mean_absolute_error: 6.7140 - accuracy: 0.0000e+00 - val_loss: 90.1907 - val_mean_absolute_error: 6.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 86.8840 - mean_absolute_error: 6.6621 - accuracy: 0.0000e+00 - val_loss: 88.5193 - val_mean_absolute_error: 6.6468 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 86.7111 - mean_absolute_error: 6.7382 - accuracy: 0.0000e+00 - val_loss: 89.7124 - val_mean_absolute_error: 6.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 86.3809 - mean_absolute_error: 6.6634 - accuracy: 0.0000e+00 - val_loss: 89.0054 - val_mean_absolute_error: 6.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 86.1452 - mean_absolute_error: 6.6779 - accuracy: 0.0000e+00 - val_loss: 89.0462 - val_mean_absolute_error: 6.6160 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 85.8981 - mean_absolute_error: 6.6465 - accuracy: 0.0000e+00 - val_loss: 88.0711 - val_mean_absolute_error: 6.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 85.7265 - mean_absolute_error: 6.6614 - accuracy: 0.0000e+00 - val_loss: 87.3272 - val_mean_absolute_error: 6.6166 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 85.8581 - mean_absolute_error: 6.6866 - accuracy: 0.0000e+00 - val_loss: 87.7588 - val_mean_absolute_error: 6.6019 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 85.5049 - mean_absolute_error: 6.6794 - accuracy: 0.0000e+00 - val_loss: 88.8134 - val_mean_absolute_error: 6.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 85.3188 - mean_absolute_error: 6.6218 - accuracy: 0.0000e+00 - val_loss: 87.4478 - val_mean_absolute_error: 6.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 85.2370 - mean_absolute_error: 6.6535 - accuracy: 0.0000e+00 - val_loss: 87.3628 - val_mean_absolute_error: 6.5882 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 85.1337 - mean_absolute_error: 6.6598 - accuracy: 0.0000e+00 - val_loss: 87.9993 - val_mean_absolute_error: 6.5805 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 85.0139 - mean_absolute_error: 6.6386 - accuracy: 0.0000e+00 - val_loss: 88.4205 - val_mean_absolute_error: 6.5777 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 85.5258 - mean_absolute_error: 6.6807 - accuracy: 0.0000e+00 - val_loss: 89.4572 - val_mean_absolute_error: 6.5804 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 85.0491 - mean_absolute_error: 6.5694 - accuracy: 0.0000e+00 - val_loss: 87.2933 - val_mean_absolute_error: 6.5745 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 84.7576 - mean_absolute_error: 6.6366 - accuracy: 0.0000e+00 - val_loss: 87.0884 - val_mean_absolute_error: 6.5737 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 84.6720 - mean_absolute_error: 6.6407 - accuracy: 0.0000e+00 - val_loss: 87.5408 - val_mean_absolute_error: 6.5672 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 84.6682 - mean_absolute_error: 6.6066 - accuracy: 0.0000e+00 - val_loss: 86.8546 - val_mean_absolute_error: 6.5729 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 84.7110 - mean_absolute_error: 6.6185 - accuracy: 0.0000e+00 - val_loss: 86.0174 - val_mean_absolute_error: 6.5910 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 84.6892 - mean_absolute_error: 6.6862 - accuracy: 0.0000e+00 - val_loss: 86.6707 - val_mean_absolute_error: 6.5719 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 84.5660 - mean_absolute_error: 6.6444 - accuracy: 0.0000e+00 - val_loss: 87.3743 - val_mean_absolute_error: 6.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 84.5300 - mean_absolute_error: 6.6358 - accuracy: 0.0000e+00 - val_loss: 88.2412 - val_mean_absolute_error: 6.5604 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 84.5432 - mean_absolute_error: 6.5736 - accuracy: 0.0000e+00 - val_loss: 86.7651 - val_mean_absolute_error: 6.5656 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 85.2736 - mean_absolute_error: 6.6502 - accuracy: 0.0000e+00 - val_loss: 86.4050 - val_mean_absolute_error: 6.5726 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 84.6559 - mean_absolute_error: 6.6733 - accuracy: 0.0000e+00 - val_loss: 87.7679 - val_mean_absolute_error: 6.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 84.5984 - mean_absolute_error: 6.6234 - accuracy: 0.0000e+00 - val_loss: 88.4530 - val_mean_absolute_error: 6.5582 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 84.4923 - mean_absolute_error: 6.5725 - accuracy: 0.0000e+00 - val_loss: 87.3933 - val_mean_absolute_error: 6.5558 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 84.3695 - mean_absolute_error: 6.6111 - accuracy: 0.0000e+00 - val_loss: 87.4527 - val_mean_absolute_error: 6.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 84.3160 - mean_absolute_error: 6.5947 - accuracy: 0.0000e+00 - val_loss: 87.0480 - val_mean_absolute_error: 6.5579 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 84.3048 - mean_absolute_error: 6.6227 - accuracy: 0.0000e+00 - val_loss: 87.4764 - val_mean_absolute_error: 6.5540 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 84.3005 - mean_absolute_error: 6.6031 - accuracy: 0.0000e+00 - val_loss: 87.6223 - val_mean_absolute_error: 6.5538 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 85.0544 - mean_absolute_error: 6.6817 - accuracy: 0.0000e+00 - val_loss: 88.6859 - val_mean_absolute_error: 6.5578 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 84.6463 - mean_absolute_error: 6.6000 - accuracy: 0.0000e+00 - val_loss: 88.9698 - val_mean_absolute_error: 6.5597 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 84.5977 - mean_absolute_error: 6.5309 - accuracy: 0.0000e+00 - val_loss: 86.9041 - val_mean_absolute_error: 6.5584 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 84.2950 - mean_absolute_error: 6.6108 - accuracy: 0.0000e+00 - val_loss: 87.0248 - val_mean_absolute_error: 6.5563 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 84.4138 - mean_absolute_error: 6.6259 - accuracy: 0.0000e+00 - val_loss: 87.1148 - val_mean_absolute_error: 6.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 84.3331 - mean_absolute_error: 6.5962 - accuracy: 0.0000e+00 - val_loss: 86.1998 - val_mean_absolute_error: 6.5710 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 84.3373 - mean_absolute_error: 6.6471 - accuracy: 0.0000e+00 - val_loss: 86.8967 - val_mean_absolute_error: 6.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 84.3308 - mean_absolute_error: 6.6007 - accuracy: 0.0000e+00 - val_loss: 86.0708 - val_mean_absolute_error: 6.5738 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    x_train_scaled,y_train,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss',patience=20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 84.13056945800781\n",
      "Test accuracy: 6.520487308502197\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(x_test,y_test,verbose=0)\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0439789cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "[22.169918 22.163311 22.186695 22.179745 22.19195  22.162163 22.159737\n",
      " 22.148796 22.169659 22.209736 22.176065 22.229319 22.233046]\n",
      "[18.8]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x_test[1:2]) \n",
    "print(prediction.flatten()) \n",
    "print(y_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "675e5e662f103e0f338aafe09665377a2c199018438416d404abaa898c5fcab6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
